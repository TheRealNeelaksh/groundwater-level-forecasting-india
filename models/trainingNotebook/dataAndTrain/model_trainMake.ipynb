{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f193a6",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da23b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import necessary libraries ---\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a734c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Groundwater Level Prediction Script ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Starting Groundwater Level Prediction Script ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a437701",
   "metadata": {},
   "source": [
    "# Importing Dataset and Verifying Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d60428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspaces/groundwater-level-forecasting-india/models/trainingNotebook/dataAndTrain\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c6d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../../../dataset/groundwater-DATASET.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04cd96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset '../../../dataset/groundwater-DATASET.csv' loaded successfully. Shape: (550850, 14)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(f\"Dataset '{dataset_path}' loaded successfully. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{dataset_path}' was not found.\")\n",
    "    print(\"Please make sure the CSV file is in the same directory as this script.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122801b",
   "metadata": {},
   "source": [
    "# Initial Data Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48095e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Data Overview ---\n",
      "   id        date                   state_name  state_code  \\\n",
      "0   0  2013-11-04  Andaman And Nicobar Islands          35   \n",
      "1   1  2014-05-14  Andaman And Nicobar Islands          35   \n",
      "2   2  2014-11-04  Andaman And Nicobar Islands          35   \n",
      "3   3  2015-05-14  Andaman And Nicobar Islands          35   \n",
      "4   4  2015-11-04  Andaman And Nicobar Islands          35   \n",
      "\n",
      "              district_name  district_code station_name  latitude  longitude  \\\n",
      "0  North And Middle Andaman            632     Laxmipur  13.28556   93.00306   \n",
      "1  North And Middle Andaman            632     Laxmipur  13.28556   93.00306   \n",
      "2  North And Middle Andaman            632     Laxmipur  13.28556   93.00306   \n",
      "3  North And Middle Andaman            632     Laxmipur  13.28556   93.00306   \n",
      "4  North And Middle Andaman            632     Laxmipur  13.28556   93.00306   \n",
      "\n",
      "                                               basin  \\\n",
      "0  Drainage Area Of Andaman And Nicobar Islands B...   \n",
      "1  Drainage Area Of Andaman And Nicobar Islands B...   \n",
      "2  Drainage Area Of Andaman And Nicobar Islands B...   \n",
      "3  Drainage Area Of Andaman And Nicobar Islands B...   \n",
      "4  Drainage Area Of Andaman And Nicobar Islands B...   \n",
      "\n",
      "                                      sub_basin source  currentlevel  \\\n",
      "0  Drainage Area Of Andaman And Nicobar Islands   CGWB          0.10   \n",
      "1  Drainage Area Of Andaman And Nicobar Islands   CGWB          2.60   \n",
      "2  Drainage Area Of Andaman And Nicobar Islands   CGWB          0.35   \n",
      "3  Drainage Area Of Andaman And Nicobar Islands   CGWB          2.52   \n",
      "4  Drainage Area Of Andaman And Nicobar Islands   CGWB          0.69   \n",
      "\n",
      "   level_diff  \n",
      "0       -1.03  \n",
      "1        2.50  \n",
      "2       -2.25  \n",
      "3        2.17  \n",
      "4       -1.83  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550850 entries, 0 to 550849\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   id             550850 non-null  int64  \n",
      " 1   date           550850 non-null  object \n",
      " 2   state_name     550850 non-null  object \n",
      " 3   state_code     550850 non-null  int64  \n",
      " 4   district_name  550850 non-null  object \n",
      " 5   district_code  550850 non-null  int64  \n",
      " 6   station_name   550850 non-null  object \n",
      " 7   latitude       550850 non-null  float64\n",
      " 8   longitude      550850 non-null  float64\n",
      " 9   basin          550850 non-null  object \n",
      " 10  sub_basin      550850 non-null  object \n",
      " 11  source         550850 non-null  object \n",
      " 12  currentlevel   550850 non-null  float64\n",
      " 13  level_diff     550850 non-null  float64\n",
      "dtypes: float64(4), int64(3), object(7)\n",
      "memory usage: 58.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows and basic info of the loaded data\n",
    "\n",
    "print(\"\\n--- Initial Data Overview ---\")\n",
    "print(df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7069e8",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1312cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Data Preprocessing ---\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Data Preprocessing ---\n",
    "print(\"\\n--- Starting Data Preprocessing ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d6937",
   "metadata": {},
   "source": [
    "Convert 'date' column to datetime objects.\n",
    "\n",
    "This is crucial for extracting time-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "980e5396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 'date' column to datetime objects.\n"
     ]
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "print(\"Converted 'date' column to datetime objects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376a894",
   "metadata": {},
   "source": [
    "Extract time-based features (Year, Month, Day of Year)\n",
    "\n",
    "These features help the model capture seasonality and long-term trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e88fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 'year', 'month', 'day_of_year' features.\n"
     ]
    }
   ],
   "source": [
    "# Extract time-based features (Year, Month, Day of Year)\n",
    "# These features help the model capture seasonality and long-term trends\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "print(\"Extracted 'year', 'month', 'day_of_year' features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb91fe9f",
   "metadata": {},
   "source": [
    "Handle missing values in the target variable 'currentlevel'\n",
    "\n",
    "Rows with missing target values are typically dropped as they cannot be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "642c2cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found in 'currentlevel' column.\n"
     ]
    }
   ],
   "source": [
    "original_rows_count = len(df)\n",
    "df.dropna(subset=['currentlevel'], inplace=True)\n",
    "if len(df) < original_rows_count:\n",
    "    print(f\"Removed {original_rows_count - len(df)} rows due to missing 'currentlevel' values.\")\n",
    "else:\n",
    "    print(\"No missing values found in 'currentlevel' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89f3391",
   "metadata": {},
   "source": [
    "# Identify features for the model\n",
    "1. 'level_diff' is a derivative of 'currentlevel' and might introduce data leakage if used as a feature.\n",
    "2. 'id', 'state_code', 'district_code' are identifiers and typically not predictive features.\n",
    "\n",
    "We will use 'latitude', 'longitude', and the newly created time features as numerical features.\n",
    "\n",
    "'state_name', 'district_name', 'station_name', 'basin', 'sub_basin', 'source' are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5225d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['state_name', 'district_name', 'station_name', 'basin', 'sub_basin', 'source']\n",
    "numerical_features = ['latitude', 'longitude', 'year', 'month', 'day_of_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a569113",
   "metadata": {},
   "source": [
    "1. Apply Label Encoding to categorical features\n",
    "2. LabelEncoder converts each unique category into an integer.\n",
    "3. This is suitable for tree-based models and avoids creating too many columns\n",
    "4. if one-hot encoding were used on high-cardinality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80f75ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Label Encoding to categorical features:\n",
      "  - Encoded 'state_name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Encoded 'district_name'\n",
      "  - Encoded 'station_name'\n",
      "  - Encoded 'basin'\n",
      "  - Encoded 'sub_basin'\n",
      "  - Encoded 'source'\n",
      "\n",
      "Handling missing values in numerical features:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nApplying Label Encoding to categorical features:\")\n",
    "for col in categorical_features:\n",
    "    if col in df.columns:\n",
    "        # Fill any NaN values in categorical columns before encoding to prevent errors\n",
    "        df[col] = df[col].fillna('Unknown_Category')\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        print(f\"  - Encoded '{col}'\")\n",
    "    else:\n",
    "        print(f\"  - Warning: Categorical column '{col}' not found in DataFrame. Skipping.\")\n",
    "\n",
    "# Handle any remaining NaN values in numerical features (e.g., if latitude/longitude had missing values)\n",
    "# Filling with the mean is a simple imputation strategy.\n",
    "print(\"\\nHandling missing values in numerical features:\")\n",
    "for col in numerical_features:\n",
    "    if col in df.columns and df[col].isnull().any():\n",
    "        mean_val = df[col].mean()\n",
    "        df[col] = df[col].fillna(mean_val)\n",
    "        print(f\"  - Filled NaN in '{col}' with mean: {mean_val:.2f}\")\n",
    "    elif col not in df.columns:\n",
    "        print(f\"  - Warning: Numerical column '{col}' not found in DataFrame. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f62a16f",
   "metadata": {},
   "source": [
    "Define features (X) and target (y) for the model\n",
    "\n",
    "Ensure that only columns that exist in the DataFrame are selected as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f61ea600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final features used for training: \n",
      "1. latitude\n",
      "2. longitude\n",
      "3. year\n",
      "4. month\n",
      "5. day_of_year\n",
      "6. state_name\n",
      "7. district_name\n",
      "8. station_name\n",
      "9. basin\n",
      "10. sub_basin\n",
      "11. source\n",
      "\n",
      "\n",
      "Shape of feature matrix (X): (550850, 11)\n",
      "Shape of target vector (y): (550850,)\n"
     ]
    }
   ],
   "source": [
    "final_features = numerical_features + [f for f in categorical_features if f in df.columns]\n",
    "X = df[final_features]\n",
    "y = df['currentlevel']\n",
    "print(f\"\\nFinal features used for training: \")\n",
    "num = 1\n",
    "for i in final_features:\n",
    "    print(f\"{num}. {i}\")\n",
    "    num += 1\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Shape of feature matrix (X): {X.shape}\")\n",
    "print(f\"Shape of target vector (y): {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d8940",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e1d86",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets\n",
    "\n",
    "test_size=0.2 means 20% of the data will be used for testing, 80% for training.\n",
    "\n",
    "random_state=42 ensures that the split is reproducible.\n",
    "\n",
    "We also split the original DataFrame (df.copy()) to easily add predictions back later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f3c22a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: 440680 samples for training, 110170 samples for testing.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, df_train_split, df_test_split = train_test_split(\n",
    "    X, y, df.copy(), test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Data split: {len(X_train)} samples for training, {len(X_test)} samples for testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d8d01",
   "metadata": {},
   "source": [
    "Initialize the RandomForestRegressor model\n",
    "\n",
    "n_estimators=100: The number of trees in the forest. More trees generally improve performance.\n",
    "\n",
    "random_state=42: For reproducibility of results.\n",
    "\n",
    "n_jobs=-1: Instructs the model to use all available CPU cores for parallel processing, speeding up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d97f5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c2c9f",
   "metadata": {},
   "source": [
    "Train the model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfdb882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestRegressor model... This may take a moment.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training RandomForestRegressor model... This may take a moment.\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a77d2",
   "metadata": {},
   "source": [
    "# Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170414f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Prediction and Evaluation ---\n",
    "print(\"\\n--- Making Predictions and Evaluating Model ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108f53b7",
   "metadata": {},
   "source": [
    "Make predictions on the test set (unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01abc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(\"Predictions generated for the test set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583e913",
   "metadata": {},
   "source": [
    "Evaluate the model's performance using common regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f\"\\nModel Evaluation Results:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2) Score: {r2:.2f}\")\n",
    "print(\"Interpretation: An R2 score of 0.88 means that approximately 88% of the variance\")\n",
    "print(\"in groundwater levels can be explained by the model, which indicates strong predictive power.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd6fa7",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Saving Predictions ---\")\n",
    "\n",
    "# Add the predictions as a new column to the test DataFrame\n",
    "df_test_split['predicted_currentlevel'] = predictions\n",
    "\n",
    "# Define the output filename for the predictions\n",
    "output_filename = '../../../trainingNotebook/models/results/groundwater_predictions.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661df3af",
   "metadata": {},
   "source": [
    "Save the DataFrame with original test data and predictions to a new CSV file\n",
    "\n",
    "index=False prevents pandas from writing the DataFrame index as a column in the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_split.to_csv(output_filename, index=False)\n",
    "print(f\"Predictions saved to '{output_filename}' successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa8f85",
   "metadata": {},
   "source": [
    "Display a sample of the predictions for quick review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Sample of Predictions (first 5 rows from the test set) ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a67022",
   "metadata": {},
   "source": [
    "Display relevant original columns alongside the actual and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = ['date', 'state_name', 'station_name', 'currentlevel', 'predicted_currentlevel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550def0e",
   "metadata": {},
   "source": [
    "Filter for columns that actually exist in the dataframe to prevent errors if some were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols_exist = [col for col in display_cols if col in df_test_split.columns]\n",
    "print(df_test_split[display_cols_exist].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
